{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5388e1a6",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting\n",
    "## Providing Examples\n",
    "Including examples in your prompts helps establish the desired format, style, and level of detail for the model's reponse.\n",
    "Few-Shot learning involves showing the model one (single-shot learning) or more (multi-shot learning) examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540a84d",
   "metadata": {},
   "source": [
    "### Coding: Few-Shot Prompting\n",
    "This technique is one of the simplest. The idea is to provide some examples to the model, so that it can learn by imitation\n",
    "E.g\n",
    "Customer service AI chat system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54704462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(usecwd=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d901d",
   "metadata": {},
   "source": [
    "Set up a `ChatPromptTemplate` based on `messages`.\n",
    "System message instructs the model on how to behave and the role it should play.\n",
    "The few-shot prompting approach is covered in the user message where two examples are provided. It always start with a customer request and a known response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304d69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a customer service specialist known for empathy, professionalism, and problem-solving. Your responses are warm yet professional, solution-focused, and always end with a concrete next step or resolution. You handle both routine inquiries and escalated issues with the same level of care\"),\n",
    "    (\"user\", \"\"\"\n",
    "     Example 1:\n",
    "     Customer: I received the wrong size shirt in my order #12345.\n",
    "     Response: I'm so sorry about the sizing mix-up with your shirt order. That must be disappointing! I can help make this right immediately. You have two options:\n",
    "        I can send you a return label and ship the correct size right away. I can process a full refund if you prefer.\n",
    "        Which options works better for you? Once you let me know, I'll take care of it right away.\n",
    "     Example 2:\n",
    "     Customer: Your website won't let me update my payment method.\n",
    "     Response: I understand how frustrating technical issues can be, especially when trying to update something as important as payment information. Let me help you with this step-by-step:\n",
    "     First, could you try clearing your browser cache and cookies?\n",
    "     If that doesn't work, I can help you update it directly from my end.\n",
    "     Could you share your account email address so I can assist you further?\n",
    "     New Request: {customer_request}\n",
    "    \"\"\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbdeeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt_template based on the template and messages\n",
    "prompr_template = ChatPromptTemplate.from_messages(messages)\n",
    "MODEL_NAME = 'openai/gpt-oss-120b'\n",
    "model = ChatGroq(model_name=MODEL_NAME)\n",
    "\n",
    "chain = prompr_template | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330acc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m really sorry to hear that your refund hasn’t arrived yet—that can be frustrating, especially after you’ve already taken the time to return the item. Let’s get this sorted out as quickly as possible.\\n\\n**Here’s what we’ll do:**\\n\\n1. **Locate your return** – I’ll check the status of the return and the associated refund in our system.  \\n2. **Confirm the payment method** – I’ll verify the account where the refund should be issued to ensure it’s being sent to the correct place.  \\n3. **Escalate if needed** – If the refund is still pending, I’ll prioritize it with our finance team so it’s processed today.\\n\\n**What I need from you to move forward:**\\n\\n- Your order number (e.g., #12345)  \\n- The email address linked to the order  \\n- The date you shipped the return (or the tracking number, if you have it)\\n\\nOnce I have those details, I’ll immediately look up the return, confirm the refund status, and get the money back to you or let you know the exact expected arrival date.  \\n\\nPlease reply with the information above, and I’ll take care of the rest right away.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"customer_request\": \"I haven't received my refund yet after returning the item 2 weeks ago\"},)\n",
    "\n",
    "response.model_dump()[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9278139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m really sorry to hear that your refund hasn’t arrived yet—that’s certainly frustrating, especially after waiting two weeks. Let’s get this sorted for you right away.\n",
      "\n",
      "**Here’s what I’ll do:**\n",
      "\n",
      "1. **Locate your return** – I’ll check the status of the return and the refund in our system.  \n",
      "2. **Confirm the refund method** – I’ll verify which payment method the refund was issued to (original card, PayPal, store credit, etc.) so we can pinpoint any possible delay.  \n",
      "3. **Escalate if needed** – If the refund hasn’t been processed, I’ll expedite it and make sure it’s completed within the next 1‑2 business days.\n",
      "\n",
      "**What I need from you to move forward:**\n",
      "\n",
      "- Your order number (e.g., #12345)  \n",
      "- The email address associated with the order  \n",
      "- The date you shipped the return and the carrier/tracking number, if you have it  \n",
      "\n",
      "If you can share those details, I’ll immediately pull up the record, verify the refund status, and get back to you with a definitive update and an expected completion time. \n",
      "\n",
      "Thank you for your patience—once I have the information, I’ll take care of this for you right away."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream({\"customer_request\": \"I haven't received my refund yet after returning the item 2 weeks ago\"}):\n",
    "    print(chunk.model_dump()[\"content\"] or \"\", end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8c294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
