{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a4d4d1",
   "metadata": {},
   "source": [
    "# Chain of Thought\n",
    "Imagine you have a task for which a model struggles to find the correct answer because it jumps to conclusions rather than thinking step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca52c8",
   "metadata": {},
   "source": [
    "`Q: Sofia has 7 apples in her basket. Her friend Emily gives her 3 more bags of apples. Each bag contains 4 apples. How many apples does Sofia have in total?`\n",
    "`step 1: calculate number of apples in the 3 bags from Emily`\n",
    "`step 2: calculate total number of apples`\n",
    "`step 3: add results of step1 and step1`\n",
    "`A: 19 apples`\n",
    "`Q: At the bakery, there are 12 cupcakes on a tray. Sarah takes 3 cupcakes for herself. hEr friend Alex then takes half of the remaining cupcakes. How many cupcakes are left on the tray?`\n",
    "`A: ??`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01efea92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(usecwd=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61168cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [(\n",
    "    \"user\", \"\"\"\n",
    "Q: Sofia has 7 apples in her basket. Her friend Emily gives her 3 more bags of apples. Each bag contains 4 apples. How many apples does Sofia have in total?\n",
    "step 1: calculate number of apples in the 3 bags from Emily\n",
    "step 2: calculate total number of apples\n",
    "step 3: add results of step1 and step1\n",
    "A: 19 apples\n",
    "Q: At the bakery, there are 12 cupcakes on a tray. Sarah takes 3 cupcakes for herself. hEr friend Alex then takes half of the remaining cupcakes. How many cupcakes are left on the tray?\n",
    "A: ??\n",
    "\"\"\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b792d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompr_template = ChatPromptTemplate.from_messages(messages)\n",
    "MODEL_NAME = 'openai/gpt-oss-120b'\n",
    "model = ChatGroq(model_name=MODEL_NAME)\n",
    "\n",
    "chain = prompr_template | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74044b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10147ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**Step‑by‑step solution**\\n'\n",
      " '\\n'\n",
      " '1. **Start with the original number of cupcakes**  \\n'\n",
      " '   - There are **12 cupcakes** on the tray.\\n'\n",
      " '\\n'\n",
      " '2. **Sarah takes 3 cupcakes**  \\n'\n",
      " '   - Remaining cupcakes = 12\\u202f−\\u202f3 = **9 cupcakes**.\\n'\n",
      " '\\n'\n",
      " '3. **Alex takes half of the remaining cupcakes**  \\n'\n",
      " '   - Half of 9 = 9\\u202f÷\\u202f2 = **4.5 cupcakes**.  \\n'\n",
      " '   - Alex takes 4.5 cupcakes.\\n'\n",
      " '\\n'\n",
      " '4. **Find how many cupcakes are left on the tray**  \\n'\n",
      " '   - Remaining cupcakes = 9\\u202f−\\u202f4.5 = **4.5 cupcakes**.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '**Answer:** There are **4.5 cupcakes** left on the tray. (If only whole '\n",
      " 'cupcakes can be taken, the problem would need whole‑number amounts; with the '\n",
      " 'numbers given, the exact mathematical result is 4.5.)')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "pprint(response.model_dump()[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01b504",
   "metadata": {},
   "source": [
    "## Zero-Shot Chain-of-Thought (CoT)\n",
    " Zero-shot CoT reasoning leverages the model's ability to break down a complex problem into smaller, manageable steps. With zero-shot prompting, you can achieve results even without prior examples.\n",
    "\n",
    " By appending the instruction `Please think step-by-step` to the prompt, the model is encouraged to articulate its reasoning process clearly and sequentially. This technique aids in solving problems by guiding the model to consider each part of the question methodically, enhancing its capacity to reach a correct answer through logical deduction.\n",
    "\n",
    " Simply append the instruction `Please think step-by-step` to the prompt to help solve the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf41e0",
   "metadata": {},
   "source": [
    "## Coding: Self-Consistency Chain-of-Thought\n",
    "Ensuring self-consistency involves running CoT model several times with the same prompt. Ideally, different paths are sampled. All results are analysed, and the popular answer is selected\n",
    "\n",
    "-Taks: `Four numbers are defined. Find the right arithmetic operations(+, -, *, /), that combines the numbers so that the result is 24`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0176b1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(usecwd=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "429930e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for zero-shot Chain-of-Thought Prompting\n",
    "def chain_of_thought_prompting(prompt: str, model_name: str = 'openai/gpt-oss-120b') -> str:\n",
    "    model = ChatGroq(model_name=model_name)\n",
    "    prompt = ChatPromptTemplate.from_messages(messages=[\n",
    "        (\"system\", \"You're a helpful assistant and answer precise and concise.\"),\n",
    "        (\"user\", f\"{prompt} \\n. Please think step by step\")\n",
    "    ])\n",
    "    print(prompt)\n",
    "    chain = prompt | model\n",
    "    return chain.invoke({}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5b7785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  self_consisitency CoT\n",
    "def self_consistency_cot(prompt: str, number_of_runs: int = 3) -> str:\n",
    "    res = []\n",
    "    for _ in range(number_of_runs):\n",
    "        current_res = chain_of_thought_prompting(prompt)\n",
    "        print(current_res)\n",
    "        res.append(current_res)\n",
    "    res_concat = \";\".join(res)\n",
    "    self_consistency_prompt = f\"You will get multiple answers in <<>>, separated by ; <<{res_concat}>> . Extract only the final equations and return the most common equation as it was provided originally. If there is no common equation, return the most likely equation.\"\n",
    "    # self_consistency_prompt_concat = \";\".join(self_consistency_prompt)\n",
    "    # messages = [\n",
    "    #     (\"system\", \"You are a helpful assistant and answer precise and concise.\"),\n",
    "    #     (\"user\", f\"{self_consistency_prompt_concat}\")\n",
    "    # ]\n",
    "    safe_text = self_consistency_prompt.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "       (\"system\", \"You are a helpful assistant and answer precise and concise.\"),\n",
    "        (\"user\", safe_text)\n",
    "    ])\n",
    "    # prompt = ChatPromptTemplate.from_messages(messages=messages)\n",
    "    model = ChatGroq(model_name='openai/gpt-oss-120b')\n",
    "    chain = prompt | model\n",
    "    return chain.invoke({}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fda028b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful assistant and answer precise and concise.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='The goal of the Game of 24 is to use the four arithmetic operations (addition, subtraction, multiplication, and division) to combine four numbers and \\nget a result of 24. The numbers are 3, 4, 6, and 8. It is mandatory to use all four numbers. Please check the final equation for correctness. Hints: Identify the basic operations,Prioritize multiplication and division, Look for combinations that make \\nnumbers divisible by 24, Consider order of operations, Use parentheses \\nstrategically, Practice with different number combinations \\n. Please think step by step'), additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**Solution**\\n\\nUse the four numbers \\\\(3,\\\\;4,\\\\;6,\\\\;8\\\\) each exactly once and combine them with the basic arithmetic operations.\\n\\n\\\\[\\n\\\\boxed{(8+4)\\\\times\\\\frac{6}{3}=24}\\n\\\\]\\n\\n**Step‑by‑step check**\\n\\n1. **Parentheses first**  \\n   \\\\[\\n   8+4 = 12\\n   \\\\]\\n\\n2. **Division**  \\n   \\\\[\\n   \\\\frac{6}{3}=2\\n   \\\\]\\n\\n3. **Multiplication** (the final operation)  \\n   \\\\[\\n   12 \\\\times 2 = 24\\n   \\\\]\\n\\nAll four numbers are used, only the allowed operations (+,\\u202f/,\\u202f×) are employed, and the result is exactly 24. Hence the equation is correct.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #%% Test\n",
    "user_prompt = \"\"\"The goal of the Game of 24 is to use the four arithmetic operations (addition, subtraction, multiplication, and division) to combine four numbers and \n",
    "get a result of 24. The numbers are 3, 4, 6, and 8. It is mandatory to use all four numbers. Please check the final equation for correctness. Hints: Identify the basic operations,Prioritize multiplication and division, Look for combinations that make \n",
    "numbers divisible by 24, Consider order of operations, Use parentheses \n",
    "strategically, Practice with different number combinations\"\"\"\n",
    " \n",
    " # %% Single CoT\n",
    "chain_of_thought_prompting(prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f46a73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful assistant and answer precise and concise.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='The goal of the Game of 24 is to use the four arithmetic operations (addition, subtraction, multiplication, and division) to combine four numbers and \\nget a result of 24. The numbers are 3, 4, 6, and 8. It is mandatory to use all four numbers. Please check the final equation for correctness. Hints: Identify the basic operations,Prioritize multiplication and division, Look for combinations that make \\nnumbers divisible by 24, Consider order of operations, Use parentheses \\nstrategically, Practice with different number combinations \\n. Please think step by step'), additional_kwargs={})]\n",
      "**Solution**\n",
      "\n",
      "\\[\n",
      "(8-6)\\times(4\\times 3)=24\n",
      "\\]\n",
      "\n",
      "**Step‑by‑step check**\n",
      "\n",
      "1. **Subtract** the numbers 8 and 6  \n",
      "   \\[\n",
      "   8-6 = 2\n",
      "   \\]\n",
      "\n",
      "2. **Multiply** the numbers 4 and 3  \n",
      "   \\[\n",
      "   4\\times 3 = 12\n",
      "   \\]\n",
      "\n",
      "3. **Multiply** the results of steps 1 and 2  \n",
      "   \\[\n",
      "   2 \\times 12 = 24\n",
      "   \\]\n",
      "\n",
      "All four numbers (8, 6, 4, 3) are used exactly once, only the allowed operations (+, –, ×, ÷) are employed, and the final result is **24**.\n",
      "input_variables=[] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful assistant and answer precise and concise.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='The goal of the Game of 24 is to use the four arithmetic operations (addition, subtraction, multiplication, and division) to combine four numbers and \\nget a result of 24. The numbers are 3, 4, 6, and 8. It is mandatory to use all four numbers. Please check the final equation for correctness. Hints: Identify the basic operations,Prioritize multiplication and division, Look for combinations that make \\nnumbers divisible by 24, Consider order of operations, Use parentheses \\nstrategically, Practice with different number combinations \\n. Please think step by step'), additional_kwargs={})]\n",
      "**Step‑by‑step reasoning**\n",
      "\n",
      "1. **Look for a product that is a multiple of 24.**  \n",
      "   \\(6 \\times 4 = 24\\).  \n",
      "   So if we can turn the remaining numbers (3 and 8) into a factor of **1**, the whole expression will stay 24.\n",
      "\n",
      "2. **Make the factor 1 from 3 and 8.**  \n",
      "   \\(\\displaystyle \\frac{8}{8}=1\\) would be ideal, but we only have one 8.  \n",
      "   Instead use the relation \\( \\frac{8}{3} \\times \\frac{3}{8}=1\\).  \n",
      "   This suggests pairing 8 with 3 in a division that later cancels out.\n",
      "\n",
      "3. **Combine the ideas:**  \n",
      "   Use the product \\(6 \\times 4\\) and multiply it by a “1” built from the other two numbers:\n",
      "\n",
      "\\[\n",
      "24 \\times \\left(\\frac{8}{3}\\times\\frac{3}{8}\\right)=24 \\times 1 = 24\n",
      "\\]\n",
      "\n",
      "4. **Simplify the expression** (the two fractions cancel each other, leaving 1).  \n",
      "   The whole expression uses each of the numbers 3, 4, 6, 8 exactly once and only the allowed operations.\n",
      "\n",
      "**Final equation**\n",
      "\n",
      "\\[\n",
      "\\boxed{(6 \\times 4)\\times\\left(\\frac{8}{3}\\times\\frac{3}{8}\\right)=24}\n",
      "\\]\n",
      "\n",
      "**Verification**\n",
      "\n",
      "- \\(6 \\times 4 = 24\\)  \n",
      "- \\(\\frac{8}{3}\\times\\frac{3}{8}= \\frac{8\\cdot3}{3\\cdot8}=1\\)  \n",
      "- \\(24 \\times 1 = 24\\)\n",
      "\n",
      "All numbers are used, the operations are valid, and the result is exactly 24.\n",
      "input_variables=[] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful assistant and answer precise and concise.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='The goal of the Game of 24 is to use the four arithmetic operations (addition, subtraction, multiplication, and division) to combine four numbers and \\nget a result of 24. The numbers are 3, 4, 6, and 8. It is mandatory to use all four numbers. Please check the final equation for correctness. Hints: Identify the basic operations,Prioritize multiplication and division, Look for combinations that make \\nnumbers divisible by 24, Consider order of operations, Use parentheses \\nstrategically, Practice with different number combinations \\n. Please think step by step'), additional_kwargs={})]\n",
      "**Solution**\n",
      "\n",
      "\\[\n",
      "(8-6)\\times(4\\times 3)=24\n",
      "\\]\n",
      "\n",
      "**Step‑by‑step check**\n",
      "\n",
      "1. **Subtract** the numbers 8 and 6  \n",
      "   \\[\n",
      "   8-6 = 2\n",
      "   \\]\n",
      "\n",
      "2. **Multiply** the numbers 4 and 3  \n",
      "   \\[\n",
      "   4\\times3 = 12\n",
      "   \\]\n",
      "\n",
      "3. **Multiply** the results of steps 1 and 2  \n",
      "   \\[\n",
      "   2 \\times 12 = 24\n",
      "   \\]\n",
      "\n",
      "All four numbers (8, 6, 4, 3) are used exactly once, and only the allowed operations (+, –, ×, ÷) with parentheses are employed. The final result is indeed **24**.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unexpected '{' in field name",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mself_consistency_cot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m res\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mself_consistency_cot\u001b[39m\u001b[34m(prompt, number_of_runs)\u001b[39m\n\u001b[32m     11\u001b[39m messages = [\n\u001b[32m     12\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant and answer precise and concise.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     13\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, self_consistency_prompt_concat)\n\u001b[32m     14\u001b[39m ]\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# safe_text = self_consistency_prompt.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# prompt = ChatPromptTemplate.from_messages([\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#    (\"system\", \"You are a helpful assistant and answer precise and concise.\"),\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#     (\"user\", safe_text)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# ])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m prompt = \u001b[43mChatPromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m model = ChatGroq(model_name=\u001b[33m'\u001b[39m\u001b[33mopenai/gpt-oss-120b\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m chain = prompt | model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:1144\u001b[39m, in \u001b[36mChatPromptTemplate.from_messages\u001b[39m\u001b[34m(cls, messages, template_format)\u001b[39m\n\u001b[32m   1095\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_messages\u001b[39m(\n\u001b[32m   1097\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   1098\u001b[39m     messages: Sequence[MessageLikeRepresentation],\n\u001b[32m   1099\u001b[39m     template_format: PromptTemplateFormat = \u001b[33m\"\u001b[39m\u001b[33mf-string\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1100\u001b[39m ) -> ChatPromptTemplate:\n\u001b[32m   1101\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[32m   1102\u001b[39m \n\u001b[32m   1103\u001b[39m \u001b[33;03m    Examples:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1142\u001b[39m \n\u001b[32m   1143\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:949\u001b[39m, in \u001b[36mChatPromptTemplate.__init__\u001b[39m\u001b[34m(self, messages, template_format, **kwargs)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    885\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    886\u001b[39m     messages: Sequence[MessageLikeRepresentation],\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m     **kwargs: Any,\n\u001b[32m    890\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    891\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[32m    892\u001b[39m \n\u001b[32m    893\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    946\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m    947\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    948\u001b[39m     messages_ = [\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m         \u001b[43m_convert_to_message_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[32m    951\u001b[39m     ]\n\u001b[32m    953\u001b[39m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[32m    954\u001b[39m     input_vars: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:1433\u001b[39m, in \u001b[36m_convert_to_message_template\u001b[39m\u001b[34m(message, template_format)\u001b[39m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_type_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     message_ = \u001b[43m_create_template_from_message_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_type_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate_format\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1437\u001b[39m     message_ = message_type_str(\n\u001b[32m   1438\u001b[39m         prompt=PromptTemplate.from_template(\n\u001b[32m   1439\u001b[39m             cast(\u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m, template), template_format=template_format\n\u001b[32m   1440\u001b[39m         )\n\u001b[32m   1441\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:1325\u001b[39m, in \u001b[36m_create_template_from_message_type\u001b[39m\u001b[34m(message_type, template, template_format)\u001b[39m\n\u001b[32m   1311\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a message prompt template from a message type and template string.\u001b[39;00m\n\u001b[32m   1312\u001b[39m \n\u001b[32m   1313\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m \u001b[33;03m    ValueError: If unexpected message type.\u001b[39;00m\n\u001b[32m   1323\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_type \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     message: BaseMessagePromptTemplate = \u001b[43mHumanMessagePromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate_format\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m   1329\u001b[39m     message = AIMessagePromptTemplate.from_template(\n\u001b[32m   1330\u001b[39m         cast(\u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m, template), template_format=template_format\n\u001b[32m   1331\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:426\u001b[39m, in \u001b[36m_StringImageMessagePromptTemplate.from_template\u001b[39m\u001b[34m(cls, template, template_format, partial_variables, **kwargs)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a class from a string template.\u001b[39;00m\n\u001b[32m    410\u001b[39m \n\u001b[32m    411\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m    ValueError: If the template is not a string or list of strings.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(template, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     prompt: StringPromptTemplate | \u001b[38;5;28mlist\u001b[39m = \u001b[43mPromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartial_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartial_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(prompt=prompt, **kwargs)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(template, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/prompt.py:289\u001b[39m, in \u001b[36mPromptTemplate.from_template\u001b[39m\u001b[34m(cls, template, template_format, partial_variables, **kwargs)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_template\u001b[39m(\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m     **kwargs: Any,\n\u001b[32m    259\u001b[39m ) -> PromptTemplate:\n\u001b[32m    260\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a prompt template from a template.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m    262\u001b[39m \u001b[33;03m    *Security warning*:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    287\u001b[39m \u001b[33;03m        The prompt template loaded from the template.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     input_variables = \u001b[43mget_template_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     partial_variables_ = partial_variables \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m partial_variables_:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/prompt_engineering/.venv/lib/python3.13/site-packages/langchain_core/prompts/string.py:266\u001b[39m, in \u001b[36mget_template_variables\u001b[39m\u001b[34m(template, template_format)\u001b[39m\n\u001b[32m    263\u001b[39m     input_variables = _get_jinja2_variables_from_template(template)\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m template_format == \u001b[33m\"\u001b[39m\u001b[33mf-string\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    265\u001b[39m     input_variables = \u001b[43m{\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mFormatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m template_format == \u001b[33m\"\u001b[39m\u001b[33mmustache\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    269\u001b[39m     input_variables = mustache_template_vars(template)\n",
      "\u001b[31mValueError\u001b[39m: unexpected '{' in field name"
     ]
    }
   ],
   "source": [
    "res = self_consistency_cot(prompt=user_prompt, number_of_runs=3)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16feddca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
